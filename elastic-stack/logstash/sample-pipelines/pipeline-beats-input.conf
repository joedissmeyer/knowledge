input {
  # listen for beats data over port 5044
  beats {
    port => 5044
  }
}

filter {
  # Sample starter grok pattern
  grok {
    match => { "message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{LOGLEVEL:loglevel}\] - %{GREEDYDATA:json_payload}"}
  }
  
  # Strategy for adding tags
  if "production" in [my-field] {
    mutate {
      add_tag => [ "prod" ]
    }
  }
  if "dev" in [my-field] {
    mutate {
      add_tag => [ "dev" ]
    }
  }
  
  # Example on using multiple operators to drop data
  if [my-field] == "foo" and [field-two] == "bar" and "password" in [message] {
      drop{}
  }
  
  # Common date match example
  date {
    match => [ "timestamp", "ISO8601", "YYYY-MM-dd HH:mm:ss.SSS"]
  }

  # Sample json input
  json {
    source => "message"
    target => "parsed_json"
  }

  # Strategy sample for how to replace data if a field exists
  if [parsed_json][applicationId] {
    mutate {
      replace => { "applicationId" => "%{[parsed_json][applicationId]}" }
    }
  }

  # Add in ADDITIONAL fields, if they exist in the log entry.
  if [parsed_json][fields][my-field] {
    mutate {
      replace => { "my-new-field-name" => "%{[parsed_json][fields][my-field]}" }
    }
  }

  # Examples when json message includes http header data
  if [parsed_json][fields][headers][x-forwarded-for] {
    mutate {
      replace => { "[headers][x-forwarded-for]" => "%{[parsed_json][fields][headers][x-forwarded-for]}" }
    }
  }
  if [parsed_json][fields][headers][x-uniwebservice-apikey] {
    mutate {
      replace => { "[headers][x-uniwebservice-apikey]" => "%{[parsed_json][fields][headers][x-uniwebservice-apikey]}" }
    }
  }
  if [parsed_json][fields][headers][x-uniwebservice-platform] {
    mutate {
      replace => { "[headers][x-uniwebservice-platform]" => "%{[parsed_json][fields][headers][x-uniwebservice-platform]}" }
    }
  }
  if [parsed_json][fields][headers][accept-language] {
    mutate {
      replace => { "[headers][accept-language]" => "%{[parsed_json][fields][headers][accept-language]}" }
    }
  }
  if [parsed_json][fields][headers][accept] {
    mutate {
      replace => { "[headers][accept]" => "%{[parsed_json][fields][headers][accept]}" }
    }
  }
  if [parsed_json][fields][headers][host] {
    mutate {
      replace => { "[headers][host]" => "%{[parsed_json][fields][headers][host]}" }
    }
  }
  if [parsed_json][fields][headers][user-agent] {
    mutate {
      replace => { "[headers][user-agent]" => "%{[parsed_json][fields][headers][user-agent]}" }
    }
  }
  if [parsed_json][fields][headers][vary] {
    mutate {
      replace => { "[headers][vary]" => "%{[parsed_json][fields][headers][vary]}" }
    }
  }

  # Final pass. Drop redundant data
  mutate {
    remove_field => [ "timestamp", "json_payload", "input_type", "parsed_json", "my-field" ]
  }
}

output {
  elasticsearch {
   hosts => ["elastic-ingest-node:9200"]
   # include document_type of _doc for ELK v6. Not needed for ELK v7
   # document_type => "_doc"
   index => "my-index-%{+YYYY.MM.dd}"
   # if using ILM, define the index setting as the ILM write alias.
   #index => "my-write-alias"
   user => "logstash-user"
   password => "BogusPassword123"
 }
}