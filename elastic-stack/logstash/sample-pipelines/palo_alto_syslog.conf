input {
  udp {
    id => "udp_palo_alto_syslog"
    port => 5520
  }
}

filter {
    grok {
      #strips timestamp and host off of the front of the syslog message leaving the raw message generated by the syslog client and saves it as "raw_message"
      #patterns_dir => "/opt/logstash/patterns"
      match => [ "message", "%{SYSLOG5424PRI}%{SYSLOGTIMESTAMP} %{HOSTNAME:syslog_host} %{GREEDYDATA:raw_message}" ]
    }

    csv {
      source => "raw_message"
      columns => [ "PaloAltoDomain","RecieveTime","SerialNum","Type","Threat-ContentType","ConfigVersion","GenerateTime","SourceAddress","DestinationAddress","NATSourceIP","NATDestinationIP","Rule","SourceUser","DestinationUser","Application","VirtualSystem","SourceZone","DestinationZone","InboundInterface","OutboundInterface","LogForwardingProfile","TimeLogged","SessionID","RepeatCount","SourcePort","DestinationPort","NATSourcePort","NATDestinationPort","Flags","IPProtocol","Action","Bytes","BytesSent","BytesRecieved","Severity","StartTime","ElapsedTimeInSec","Category","Direction","SequenceNumber","ActionFlags","SourceLocation","DestinationLocation","pcap_id","pkts_sent","pkts_recieved","session_end_reason","cloud","url_index","userAgent","fileType","unknown","syslogDeviceName","ActionSource","flag_captive_portal","flag_proxy_transaction","flag_decrypted","flag_server_to_server","flag_server_to_client","flag_symmetric_return","flag_mirrored","flag_tunnel_inspected","flag_mptcp_options","flag_recon_excluded","flag_decrypt_forwarded" ]
    }
    date {
      timezone => "America/New_York"
      match => [ "GenerateTime", "YYYY/MM/dd HH:mm:ss" ]
    }
    #convert fields to proper format
    mutate {
      convert => [ "Bytes", "integer" ]
      convert => [ "BytesReceived", "integer" ]
      convert => [ "BytesSent", "integer" ]
      convert => [ "ElapsedTimeInSec", "integer" ]
      convert => [ "geoip.area_code", "integer" ]
      convert => [ "geoip.dma_code", "integer" ]
      convert => [ "geoip.latitude", "float" ]
      convert => [ "geoip.longitude", "float" ]
      convert => [ "NATDestinationPort", "integer" ]
      convert => [ "NATSourcePort", "integer" ]
      convert => [ "Packets", "integer" ]
      convert => [ "pkts_received", "integer" ]
      convert => [ "pkts_sent", "integer" ]
      convert => [ "seqno", "integer" ]
      gsub => [ "Rule", " ", "_",
                "Application", "( |-)", "_" ]
      remove_field => [ "message","raw_message","syslog_host","unknown","flag_captive_portal","flag_proxy_transaction","flag_decrypted","flag_server_to_server","flag_server_to_client","flag_symmetric_return","flag_mirrored","flag_tunnel_inspected","flag_mptcp_options","flag_recon_excluded","flag_decrypt_forwarded" ]
    }

  #Geolocate logs that have SourceAddress and if that SourceAddress is a non-RFC1918 address
  if [SourceAddress] and [SourceAddress] !~ "(^127\.0\.0\.1)|(^10\.)|(^172\.1[6-9]\.)|(^172\.2[0-9]\.)|(^172\.3[0-1]\.)|(^192\.168\.)|(^169\.254\.)" {
      geoip {
           source => "SourceAddress"
           target => "SourceGeo"
      }
      #Delete 0,0 in SourceGeo.location if equal to 0,0
      if ([SourceGeo.location] and [SourceGeo.location] =~ "0,0") {
        mutate {
          replace => [ "SourceGeo.location", "" ]
        }
      }
    }

  #Geolocate logs that have DestinationAddress and if that DestinationAddress is a non-RFC1918 address
  if [DestinationAddress] and [DestinationAddress] !~ "(^127\.0\.0\.1)|(^10\.)|(^172\.1[6-9]\.)|(^172\.2[0-9]\.)|(^172\.3[0-1]\.)|(^192\.168\.)|(^169\.254\.)" {
      geoip {
           source => "DestinationAddress"
           target => "DestinationGeo"
      }
      #Delete 0,0 in DestinationGeo.location if equal to 0,0
      if ([DestinationGeo.location] and [DestinationGeo.location] =~ "0,0") {
        mutate {
          replace => [ "DestinationAddress.location", "" ]
        }
      }
    }

  #Takes the 5-tuple of source address, source port, destination address, destination port, and protocol and does a SHA1 hash to fingerprint the flow.  This is a useful
  #way to be able to do top N terms queries on flows, not just on one field.
  if [SourceAddress] and [DestinationAddress] {
    fingerprint {
      concatenate_sources => true
      method => "SHA1"
      key => "logstash"
      source => [ "SourceAddress", "SourcePort", "DestinationAddress", "DestinationPort", "IPProtocol" ]
    }
  }
}

output {
  elasticsearch {
   hosts => ["elastic-ingest-node:9200"]
   # include document_type of _doc for ELK v6. Not needed for ELK v7
   # document_type => "_doc"
   index => "my-index-%{+YYYY.MM.dd}"
   # if using ILM, define the index setting as the ILM write alias.
   #index => "my-write-alias"
   user => "logstash-user"
   password => "BogusPassword123"
 }
}