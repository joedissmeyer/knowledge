# Pipeline for MS Exchange server message tracking logs
# Message tracking logs will be in CSV format.

input {
  beats {
    port => 5044
  }
}

filter {
  # Drop message if it is a commented line in the log
  if [message] =~ "^#" {
    drop {}
  }
  csv {
    columns => ['date-time','client-ip','client-hostname','server-ip','server-hostname','source-context','connector-id','source','event-id','internal-message-id','message-id','network-message-id','recipient-address','recipient-status','total-bytes','recipient-count','related-recipient-address','reference','message-subject','sender-address','return-path','message-info','directionality','tenant-id','original-client-ip','original-server-ip','custom-data','transport-traffic-type','log-id','schema-version']
  }
	grok {      
    match => [ "message", "%{TIMESTAMP_ISO8601:timestamp}" ]
  }
	mutate {
    convert => [ "total-bytes", "integer" ]
	  convert => [ "recipient-count", "integer" ]
	  split => [ "recipient-address", ";"]
	  split => [ "source-context", ";" ]
	  split => [ "custom-data", ";" ]
  }

  date {
    match => [ "timestamp", "ISO8601" ]
  }
  
  mutate {
    remove_field => [ "message", "connector-id", "custom-data", "date-time", "input_type", "log-id", "message-id", "message-info", "message-subject", "network-message-id", "offset", "recipient-address", "reference", "related-recipient-address", "return-path", "schema-version", "sender-address", "source-context", "tenant-id", "transport-traffic-type", "type" ]
  }
}

output {
  elasticsearch {
   hosts => ["elastic-ingest-node:9200"]
   # include document_type of _doc for ELK v6. Not needed for ELK v7
   # document_type => "_doc"
   index => "my-index-%{+YYYY.MM.dd}"
   # if using ILM, define the index setting as the ILM write alias.
   #index => "my-write-alias"
   user => "logstash-user"
   password => "BogusPassword123"
 }
}